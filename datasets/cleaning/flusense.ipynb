{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from os.path import join, exists, splitext, basename, dirname, isdir\n",
    "from os import listdir, symlink, makedirs\n",
    "from shutil import copyfile\n",
    "from praatio import tgio\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "from cac.utils.io import load_json, write_txt\n",
    "from cac.utils.pandas import apply_antifilters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where the data resides\n",
    "data_root = '/data/flusense/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src and destination directories\n",
    "load_dir = join(data_root, 'raw')\n",
    "save_root = join(data_root, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(save_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_audio_dir = join(load_dir, 'audio')\n",
    "load_annotation_dir = join(load_dir, 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_audio_dir = join(save_root, 'audio')\n",
    "makedirs(save_audio_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important check: find out files that are unreadable via `EOFError` (can't be discovered by `librosa`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(load_audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_files = []\n",
    "\n",
    "for file in tqdm(files, desc='Checking valid files'):\n",
    "    fpath = f'/data/flusense/raw/audio/{file}'\n",
    "    try:\n",
    "        fs,signal = wav.read(fpath)\n",
    "    except:\n",
    "        invalid_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(invalid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = list(set(files) - set(invalid_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create symlinks to the original .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists(fname):\n",
    "    fpath = join(\"/data/flusense/FluSense-data/FluSense-audio/\", fname)\n",
    "    return exists(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_exists(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in files if check_exists(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(files, desc='Creating symlinks processed/ <- raw/'):\n",
    "    dest = join(save_audio_dir, file)\n",
    "    if not exists(dest):\n",
    "        symlink(join(load_audio_dir, file), dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating symlinks for annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation files are .TextGrid => using library praatio to read them\n",
    "\n",
    "Steps for each file:\n",
    "\n",
    "* Checked that each annotation object satisfies len(annotation.tierNameList) == 1\n",
    "* Extract the list of entries\n",
    "* For each entry, add the label of that entry to the list of classification labels for that file and add each interval to the list of intervals for that file\n",
    "\n",
    "Final goal is to obtain classification_targets and segmentation_targets for all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_targets = []\n",
    "segmentation_targets = []\n",
    "\n",
    "for file in files:\n",
    "    _classification_targets = set()\n",
    "    _segmentation_targets = defaultdict(list)\n",
    "\n",
    "    text_grid = tgio.openTextgrid(join(load_annotation_dir, file.replace('wav', 'TextGrid')))\n",
    "    \n",
    "    # ensure that only one name in the namelist\n",
    "    assert len(text_grid.tierNameList) == 1\n",
    "    \n",
    "    t_name = text_grid.tierNameList[0]\n",
    "    \n",
    "    # this is a list of entries\n",
    "    # each entry consists of an interval\n",
    "    entry_list = text_grid.tierDict[t_name].entryList\n",
    "    \n",
    "    for entry in entry_list:\n",
    "        label = entry.label\n",
    "        start = entry.start\n",
    "        end = entry.end\n",
    "        \n",
    "        # add label to classification targets for that file\n",
    "        _classification_targets.add(label)\n",
    "        # add interval to segmentation targets for that file\n",
    "        _segmentation_targets[label].append([start, end])\n",
    "    \n",
    "    classification_targets.append(list(_classification_targets))\n",
    "    segmentation_targets.append(dict(_segmentation_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [0.0 for _ in files]\n",
    "ends = [librosa.get_duration(filename=join(save_audio_dir, x)) for x in tqdm(files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .wav from the filenames\n",
    "files = [splitext(file)[0] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe storing the data\n",
    "df = pd.DataFrame({'file': files, 'classification': classification_targets, 'segmentation': segmentation_targets, 'start': starts, 'end': ends})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invalid/unreadable files\n",
    "df = apply_antifilters(df, {'file': [x.split('.wav')[0] for x in invalid_files]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "annotation_save_path = join(save_root, 'annotation.csv')\n",
    "df.to_csv(annotation_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Annotation columns: \\n \\\n",
    "`classification`: valid labels = [cough, sneeze, sniffle, throat-clearing,\\\n",
    " speech, etc (i.e everything else)] \\n \\\n",
    "`segmentation`: {label: list of lists, each marking the start and end of the\\\n",
    " interval in which the label is occuring in the file}\"\n",
    "\n",
    "with open(join(save_root, 'description.txt'), 'w') as f:\n",
    "    f.write(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
